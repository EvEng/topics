## Team Members
- Daniel Barry
- Brett Bass
- Evan Ezell
- Trish Goedecke
- Dustin McAfee
- Jesse Piburn

## Description
We wanted to focus on the techniques and technology stacks that are used to ingest, store, and compute large volumes of data


## General Topics / Technologies

### Storage
- HDFS
- S3
- HBase
- OLTP vs OLAP
- Apache Parquet
- Apache Arrow

### Compute
- Hadoop MapReduce
- Apache Spark
- Apache Flink
- Apache Hive

### Messaging
- Apache Kafka
- ActiveMQ

### Geospatial
- Raster vs Vector
- Geospatial Indexing
- Cloud optimized geospatial data formats


## Presentations

### Application of FDA High-Performance Integrated Virtual Environment (HIVE) Supercomputer to Analysis of Cardiac Safety Clinical Trials
- Dustin McAfee
- 15-20 minutes
- Will be presenting with slides from a previous presentation,
    which covers a porting of an existing Electrocardiogram Analysis Software to a
    highly parallelized environment, the HIVE Supercomputer. The powerpoint slides were
    not altered, because this presentation was approved to be shown out of circuit along with
    the poster that was presented with it at the Office of Clinical Pharmacology (FDA/OCP) Day on December 5th, 2016.
- This presentation is available from a collaboration between the Center for Drug Evaluation and Research (FDA/CDER), the Division of Applied Regulatory Science (FDA/CDER/DARS), and 
    the Center for Biologics Evaluation and Research (FDA/CBER). The open source project is available at https://github.com/FDA/ecglib.
- Will be ready 1/22.

### Introduction to using UT's NICS ACF Computing Cluster
- Trish Goedecke
- 10-15 minutes
- PowerPoint presentation on the basics of logging on and getting started using the cluster
- This introduction will be ready 1/29. Hope to follow later in semester with more advanced use, ie, parallel processing.
